# Differential_Privacy
This project consists of different models trained under differential privacy for the purpose of classifying the CIFAR-10 dataset.

Differential Privacy is a privacy preserving technique used in machine learning models by adding noise to the gradients of the model.
For the purpose of this project, different models were trained and tested under differntial privacy to see which performs best. Two metrics, Epsilon (ϵ) and Delta ()), based on Mironov's Rényi Differential Privacy, were used to assess model's privacy performance. This project's allowed privacy budget is as follows: Epsilon: ϵ≤5.0, with Delta set toδ==10. (-5).

The system environment that was used to evaluate this project comprised of an Apple M1/M1 pro GPU (Metal GPUFamily Apple 7) operating on macOS and TensorFlow Privacy as the deep learning framework coded in Python3.

## Team Members
1.	Sanika Katekar; sk56865@uga.edu
2.	Soham Sajekar; ss92078@uga.edu
